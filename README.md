# Interpretability: Towards Explainable Machine Learning
#### Yassin Bahid

### Summary:
Deep Learning Methods have gained in popularity recently in both commercial and industrial uses and Scientific areas. While the focus has always been on the accuracy, there is an increasing demand for an explanation of the way models function and arrives at decisions. In scientific fields, explainability is a prerequisite. Yet, there has been a lack of explainability and interpretability of the model. We shall first define what we mean by interpretability, before looking at different methods that try to achieve it. We will focus solely on Image classification Deep networks such as VGG and Resnet.


### File Structure:
Interp.ipynb: Jupyter Notebook containing report.

#### Reference:
Roscher, Ribana, et al. “Explainable Machine Learning for Scientific Insights and Discoveries.” IEEE Access, vol. 8, 2020, pp. 42200–16. arXiv.org, https://doi.org/10.1109/ACCESS.2020.2976199.

Hue, Antoine, Neural Network Interpretability — A review, https://towardsdatascience.com/dense-or-convolutional-part-2-interpretability-c310a9fd99a5#:~:text=DNN%20are%20based%20on%20simple,lack%20of%20transparency%20by%20Roscher.

